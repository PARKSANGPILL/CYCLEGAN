{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c6a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844ca360",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_x = glob('./monet2photo/trainB/*.jpg')[:1193]\n",
    "path_y = glob('./monet2photo/trainA/*.jpg')\n",
    "test_input = tf.io.read_file('./monet2photo/testB/2014-08-03 17_39_45.jpg')\n",
    "test_input = tf.image.decode_jpeg(test_input, channels=3)\n",
    "BATCH_SIZE = 1\n",
    "epochs = 200\n",
    "initializer = tf.random_normal_initializer(0., 0.02)  #Weights are initialized from aGaussian distribution N (0, 0.02).\n",
    "#We train our networks from scratch, with a learning rate of 0.0002.\n",
    "learning_rate = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=2e-4,\n",
    "                                                          decay_steps=250000,\n",
    "                                                          alpha=0)\n",
    "beta_1 = 0.5\n",
    "alpha = 0.2  #We use leaky ReLUs with a slope of 0.2\n",
    "LAMBDA = 10  #We set λ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e865ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_x, path_y):\n",
    "    #real_x\n",
    "    img_x = tf.io.read_file(path_x)\n",
    "    img_x = tf.image.decode_jpeg(img_x, channels=3)\n",
    "    img_x = tf.image.resize(img_x, [256, 256])\n",
    "    \n",
    "    #normalize\n",
    "    img_x = tf.cast(img_x, dtype=tf.float32)\n",
    "    img_x = (img_x / 127.5) - 1\n",
    "    \n",
    "    #real_y\n",
    "    img_y = tf.io.read_file(path_y)\n",
    "    img_y = tf.image.decode_jpeg(img_y, channels=3)\n",
    "    img_y = tf.image.resize(img_y, [256, 256])\n",
    "    \n",
    "    #normalize\n",
    "    img_y = tf.cast(img_y, dtype=tf.float32)\n",
    "    img_y = (img_y / 127.5) - 1\n",
    "    \n",
    "    #randomflip\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img_x = tf.image.random_flip_left_right(img_x)\n",
    "        img_y = tf.image.random_flip_left_right(img_y)\n",
    "    return img_x, img_y\n",
    "\n",
    "def generate_save_img(model, epoch, test_input):\n",
    "    test_input = tf.expand_dims(test_input, axis=0)\n",
    "    preds = model(test_input, training=False)\n",
    "    preds = (preds + 1) * 127.5\n",
    "    preds = tf.cast(preds, dtype=tf.uint8)\n",
    "    \n",
    "    plt.figure(figsize=(7,7))\n",
    "    display_list = [test_input[0], preds[0]]\n",
    "    title = ['Input Image', 'Predicted image']\n",
    "    for i in range(2):\n",
    "        plt.subplot(1,2,i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "    plt.savefig('./CYCLEGAN/image/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7162af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((path_x, path_y))\n",
    "train_dataset = train_dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(10000)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2f8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reflection padding was used to reduce artifacts\n",
    "#c7s1-k denote a 7×7 Convolution-InstanceNormReLU layer with k filters and stride 1\n",
    "def c7s1_k(inputs, filters, kernel_size, strides, padding, kernel_initializer):\n",
    "    \n",
    "    rpad = tf.pad(inputs, [[0,0],[3,3],[3,3],[0,0]], 'REFLECT')\n",
    "    conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, \n",
    "                                  padding=padding, \n",
    "                                  kernel_initializer=kernel_initializer)(rpad)\n",
    "    norm = tfa.layers.InstanceNormalization()(conv)\n",
    "    relu = tf.keras.layers.ReLU()(norm)\n",
    "    \n",
    "    return relu\n",
    "\n",
    "#dk denotes a 3 × 3 Convolution-InstanceNorm-ReLU layer with k filters and stride 2\n",
    "def dk(inputs, filters, kernel_size, strides, padding, kernel_initializer):\n",
    "    \n",
    "    rpad = tf.pad(inputs, [[0,0],[1,1],[1,1],[0,0]], 'REFLECT')  \n",
    "    conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, \n",
    "                                  padding=padding, \n",
    "                                  kernel_initializer=kernel_initializer)(rpad)\n",
    "    norm = tfa.layers.InstanceNormalization()(conv)\n",
    "    relu = tf.keras.layers.ReLU()(norm)\n",
    "    \n",
    "    return relu\n",
    "\n",
    "#Rk denotes a residual block that contains two 3 × 3 convolutional layers with the same number of filters on both layer\n",
    "def Rk(inputs, filters, kernel_size, strides, padding, kernel_initializer):\n",
    "    \n",
    "    rpad1 = tf.pad(inputs, [[0,0],[1,1],[1,1],[0,0]], 'REFLECT')  \n",
    "    Rk1 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                               padding='same', \n",
    "                               kernel_initializer=kernel_initializer,\n",
    "                               activation=\"relu\")(rpad1)\n",
    "    rpad2 = tf.pad(Rk1, [[0,0],[1,1],[1,1],[0,0]], 'REFLECT')  \n",
    "    Rk2 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                               padding=padding,\n",
    "                               kernel_initializer=kernel_initializer)(Rk1)\n",
    "    x = tf.keras.layers.Add()([inputs, Rk2])\n",
    "    \n",
    "    return x\n",
    "\n",
    "#uk denotes a 3 × 3 fractional-strided-ConvolutionInstanceNorm-ReLU layer with k filters and stride 1/2.\n",
    "def uk(inputs, filters, kernel_size, strides, padding, kernel_initializer):\n",
    "      \n",
    "    conv = tf.keras.layers.Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides, \n",
    "                                           padding=padding,\n",
    "                                           kernel_initializer=kernel_initializer)(inputs)\n",
    "    norm = tfa.layers.InstanceNormalization()(conv)\n",
    "    relu = tf.keras.layers.ReLU()(norm)\n",
    "    \n",
    "    return relu\n",
    "\n",
    "#Ck denote a 4 × 4 Convolution-InstanceNorm-LeakyReLU layer with k filters and stride 2\n",
    "def ck(inputs, filters, kernel_size, strides, padding, kernel_initializer, alpha):\n",
    "    \n",
    "    conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, \n",
    "                                  padding=padding,\n",
    "                                  kernel_initializer=kernel_initializer)(inputs)\n",
    "    norm = tfa.layers.InstanceNormalization()(conv)\n",
    "    Lrelu = tf.keras.layers.LeakyReLU(alpha=alpha)(norm)\n",
    "    \n",
    "    return Lrelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3135fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "\n",
    "    c7s1_64 = c7s1_k(inputs, filters=64, kernel_size=7, strides=1, padding='valid', kernel_initializer=initializer)\n",
    "    \n",
    "    d128 = dk(c7s1_64, filters=128, kernel_size=3, strides=2, padding='valid', kernel_initializer=initializer)\n",
    "    d256 = dk(d128, filters=256, kernel_size=3, strides=2, padding='valid', kernel_initializer=initializer)\n",
    "    \n",
    "    R256_1 = Rk(d256, filters=256, kernel_size=3, strides=1, padding='valid', kernel_initializer=initializer)\n",
    "    R256_2 = Rk(R256_1, filters=256, kernel_size=3, strides=1, padding='valid', kernel_initializer=initializer)\n",
    "    R256_3 = Rk(R256_2, filters=256, kernel_size=3, strides=1, padding='valid', kernel_initializer=initializer)\n",
    "    R256_4 = Rk(R256_3, filters=256, kernel_size=3, strides=1, padding='valid', kernel_initializer=initializer)\n",
    "    R256_5 = Rk(R256_4, filters=256, kernel_size=3, strides=1, padding='valid', kernel_initializer=initializer)\n",
    "    R256_6 = Rk(R256_5, filters=256, kernel_size=3, strides=1, padding='valid', kernel_initializer=initializer)\n",
    "    R256_7 = Rk(R256_6, filters=256, kernel_size=3, strides=1, padding='valid', kernel_initializer=initializer)\n",
    "    R256_8 = Rk(R256_7, filters=256, kernel_size=3, strides=1, padding='valid', kernel_initializer=initializer)\n",
    "    R256_9 = Rk(R256_8, filters=256, kernel_size=3, strides=1, padding='valid', kernel_initializer=initializer)\n",
    "    \n",
    "    u128 = uk(R256_9, filters=128, kernel_size=3, strides=2, padding='same', kernel_initializer=initializer)\n",
    "    u64 = uk(u128, filters=64, kernel_size=3, strides=2, padding='same', kernel_initializer=initializer)\n",
    "    \n",
    "    c7s1_3 = tf.keras.layers.Conv2D(filters=3, kernel_size=7, strides=1, \n",
    "                                    padding='same', \n",
    "                                    kernel_initializer=initializer,\n",
    "                                    activation='tanh')(u64)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=c7s1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b35bb6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "    \n",
    "    c64 = tf.keras.layers.Conv2D(filters=64, kernel_size=4, strides=2,\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=initializer)(inputs)  #We do not use InstanceNorm for the first C64 layer\n",
    "    Lrelu = tf.keras.layers.LeakyReLU(alpha=alpha)(c64)\n",
    "    c128 = ck(Lrelu, filters=128, kernel_size=4, strides=2, padding='same', kernel_initializer=initializer, alpha=alpha)\n",
    "    drop1 = tf.keras.layers.Dropout(0.3)(c128)\n",
    "    c256 = ck(drop1, filters=256, kernel_size=4, strides=2, padding='same', kernel_initializer=initializer, alpha=alpha)\n",
    "    drop2 = tf.keras.layers.Dropout(0.3)(c256)\n",
    "    c512 = ck(drop2, filters=512, kernel_size=4, strides=2, padding='same', kernel_initializer=initializer, alpha=alpha)\n",
    "    drop3 = tf.keras.layers.Dropout(0.3)(c512)\n",
    "    #After the last layer, we apply a convolution to produce a 1-dimensional output\n",
    "    outputs = tf.keras.layers.Conv2D(filters=1, kernel_size=4, strides=2, padding='same', activation='sigmoid')(drop3)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e918ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator()\n",
    "F = generator()\n",
    "Dx = discriminator()\n",
    "Dy = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba8eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beloss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "l1loss = tf.keras.losses.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d5ade20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_loss(real_img, fake_img):\n",
    "    real = beloss(tf.ones_like(real_img), real_img)\n",
    "    fake = beloss(tf.zeros_like(fake_img), fake_img)\n",
    "    total = real + fake\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d241c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_loss(fake_img):\n",
    "    return beloss(tf.ones_like(fake_img), fake_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "853709e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_loss(real_img, cycle_img):\n",
    "    loss = l1loss(real_img, cycle_img)\n",
    "    return LAMBDA * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ef90599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(real_img, same_img):\n",
    "    loss = l1loss(real_img, same_img)\n",
    "    return LAMBDA * 0.5 * loss  #identity mapping loss was 0.5λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "172c91ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1)\n",
    "f_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1)\n",
    "dx_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1)\n",
    "dy_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b6e4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './CYCLEGAN/checkpoint'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(G=G, \n",
    "                                 F=F, \n",
    "                                 Dx=Dx,\n",
    "                                 Dy=Dy,\n",
    "                                 g_optimizer=g_optimizer,\n",
    "                                 f_optimizer=f_optimizer,\n",
    "                                 dx_optimizer=dx_optimizer,\n",
    "                                 dy_optimizer=dy_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1bab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        \n",
    "        fake_y = G(real_x, training=True)\n",
    "        cycle_x = F(fake_y, training=True)\n",
    "        \n",
    "        fake_x = F(real_y, training=True)\n",
    "        cycle_y = G(fake_x, training=True)\n",
    "        \n",
    "        same_x = F(real_x, training=True)\n",
    "        same_y = G(real_y, training=True)\n",
    "        \n",
    "        d_real_x = Dx(real_x, training=True)\n",
    "        d_real_y = Dy(real_y, training=True)\n",
    "        \n",
    "        d_fake_x = Dx(fake_x, training=True)\n",
    "        d_fake_y = Dy(fake_y, training=True)\n",
    "        \n",
    "        gen_g_loss = g_loss(d_fake_y)\n",
    "        gen_f_loss = g_loss(d_fake_x)\n",
    "        total_cycle_loss = cycle_loss(real_x, cycle_x) + cycle_loss(real_y, cycle_y)\n",
    "        \n",
    "        total_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "        total_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
    "        dx_loss = d_loss(d_real_x, d_fake_x)\n",
    "        dy_loss = d_loss(d_real_y, d_fake_y)\n",
    "        \n",
    "    g_gradients = tape.gradient(total_g_loss, G.trainable_variables)\n",
    "    f_gradients = tape.gradient(total_f_loss, F.trainable_variables)\n",
    "    dx_gradients = tape.gradient(dx_loss, Dx.trainable_variables)\n",
    "    dy_gradients = tape.gradient(dy_loss, Dy.trainable_variables)\n",
    "    \n",
    "    g_optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))\n",
    "    f_optimizer.apply_gradients(zip(f_gradients, F.trainable_variables))\n",
    "    dx_optimizer.apply_gradients(zip(dx_gradients, Dx.trainable_variables))\n",
    "    dy_optimizer.apply_gradients(zip(dy_gradients, Dy.trainable_variables))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ba6dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        for real_x, real_y in dataset:\n",
    "            train_step(real_x, real_y)\n",
    "            \n",
    "        generate_save_img(G, epoch+1, test_input)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            \n",
    "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c1332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train(train_dataset, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
